{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dbacf660-c547-4325-841f-db511bd0994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "parent_directory = os.path.abspath('..')\n",
    "sys.path.append(parent_directory)\n",
    "from src import data as d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "038bbac5-6192-48ba-8230-bc6a26badb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLoader = d.DataLoader(\"../localdata/\")\n",
    "(train_images, train_labels_ix, train_labels, \n",
    "           test_images, test_labels_ix, test_labels, \n",
    "           shifted_images, shifted_labels_ix, shifted_labels,\n",
    "           num_classes ) = dataLoader.load_data('CIFAR10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3acd81a-880e-49d3-99b1-cc151f6c9829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(metric):\n",
    "    \"\"\"\n",
    "    Compute stat desc of a metric\n",
    "    \"\"\"\n",
    "    stats = dict()\n",
    "    stats['mean'] = np.mean(metric)\n",
    "    stats['std'] = np.std(metric)\n",
    "    stats['min'] = np.min(metric)\n",
    "    stats['max'] = np.max(metric)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ffd4f6-031a-4636-9441-251590f87efe",
   "metadata": {},
   "source": [
    "# Single models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "099fb254-40ce-4a24-8a6d-7de07dcbe293",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = \"../results/raw/single\"\n",
    "\n",
    "acc = []\n",
    "iou = []\n",
    "f1 = []\n",
    "ind_pred_classes = None\n",
    "ind_pred_probs = list()\n",
    "acc_shifted = []\n",
    "iou_shifted = []\n",
    "f1_shifted = []\n",
    "ind_pred_classes_shifted = None\n",
    "ind_pred_shifted_probs = list()\n",
    "\n",
    "for f in os.listdir(models_path):\n",
    "    if f.endswith(\"npy\"):\n",
    "        with open(os.path.join(models_path, f), 'rb') as npy:\n",
    "            pred = np.load(npy)\n",
    "            pred_shifted = np.load(npy)\n",
    "\n",
    "        ind_pred_probs.append(pred)\n",
    "        ind_pred_shifted_probs.append(pred_shifted)\n",
    "        pred_classes = np.argmax(pred, axis=1)\n",
    "        pred_classes_shifted = np.argmax(pred_shifted, axis=1)\n",
    "        \n",
    "        if ind_pred_classes is None:\n",
    "            ind_pred_classes = pred_classes\n",
    "        else:\n",
    "            ind_pred_classes = np.vstack([ind_pred_classes, pred_classes])\n",
    "            \n",
    "        if ind_pred_classes_shifted is None:\n",
    "            ind_pred_classes_shifted = pred_classes_shifted\n",
    "        else:\n",
    "            ind_pred_classes_shifted = np.vstack([ind_pred_classes_shifted, pred_classes_shifted])\n",
    "            \n",
    "        acc.append(metrics.accuracy_score(test_labels_ix, pred_classes))\n",
    "        iou.append(metrics.jaccard_score(test_labels_ix, pred_classes, average=\"weighted\"))\n",
    "        f1.append(metrics.f1_score(test_labels_ix, pred_classes, average=\"weighted\"))\n",
    "        \n",
    "        acc_shifted.append(metrics.accuracy_score(shifted_labels_ix, pred_classes_shifted))\n",
    "        iou_shifted.append(metrics.jaccard_score(shifted_labels_ix, pred_classes_shifted, average=\"weighted\"))\n",
    "        f1_shifted.append(metrics.f1_score(shifted_labels_ix, pred_classes_shifted, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f4be179-13b3-40da-baf7-85ca04bd499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_acc = compute_stats(acc)\n",
    "stats_iou = compute_stats(iou)\n",
    "stats_f1 = compute_stats(f1)\n",
    "\n",
    "stats_acc_shifted = compute_stats(acc_shifted)\n",
    "stats_iou_shifted = compute_stats(iou_shifted)\n",
    "stats_f1_shifted = compute_stats(f1_shifted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e151516-f68e-417c-a50c-91e382b51d13",
   "metadata": {},
   "source": [
    "# Deep ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14e9740d-84cd-41da-9574-e20f7a63f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_len = 12\n",
    "ens_set = np.random.permutation(range(len(ind_pred_probs)))[0:ens_len]\n",
    "\n",
    "ind_pred_classes_ens = ind_pred_classes[ens_set]\n",
    "ind_pred_classes_shifted_ens = ind_pred_classes_shifted[ens_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea154af6-6f40-4282-b99f-57d88663d9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mode = stats.mode(ind_pred_classes_ens).mode    \n",
    "\n",
    "pred_mode_shifted = stats.mode(ind_pred_classes_shifted_ens).mode\n",
    "\n",
    "mode_acc = metrics.accuracy_score(test_labels_ix, pred_mode)\n",
    "mode_iou = metrics.jaccard_score(test_labels_ix, pred_mode, average=\"weighted\")\n",
    "mode_f1 = metrics.f1_score(test_labels_ix, pred_mode, average=\"weighted\")\n",
    "\n",
    "mode_acc_shifted = metrics.accuracy_score(shifted_labels_ix, pred_mode_shifted)\n",
    "mode_iou_shifted = metrics.jaccard_score(shifted_labels_ix, pred_mode_shifted, average=\"weighted\")\n",
    "mode_f1_shifted = metrics.f1_score(shifted_labels_ix, pred_mode_shifted, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f6331e92-a39f-4bdc-b6b0-6eace4665d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance\n",
    "tmp = np.stack(ind_pred_probs, axis=1)\n",
    "var_samp_class = np.var(tmp, axis=1)\n",
    "var_samp = np.sum(var_samp_class, axis=1)\n",
    "var_ens = np.mean(var_samp)\n",
    "    \n",
    "tmp = np.stack(ind_pred_shifted_probs, axis=1)\n",
    "var_samp_class = np.var(tmp, axis=1)\n",
    "var_samp = np.sum(var_samp_class, axis=1)\n",
    "var_ens_shifted = np.mean(var_samp)\n",
    "\n",
    "# entropy\n",
    "l_z = None\n",
    "for i in range(ind_pred_classes.shape[0]):\n",
    "    if l_z is None:\n",
    "        l_z = (ind_pred_classes[i,:] == test_labels_ix[:,0]) * 1\n",
    "    else:\n",
    "        l_z = l_z + (ind_pred_classes[i,:] == test_labels_ix[:,0]) * 1\n",
    "\n",
    "entropy_ens = np.mean(np.minimum(l_z, ind_pred_classes.shape[0] - l_z) / (ind_pred_classes.shape[0] - np.ceil(ind_pred_classes.shape[0]/2)))\n",
    "    \n",
    "l_z = None\n",
    "for i in range(ind_pred_classes_shifted.shape[0]):\n",
    "    if l_z is None:\n",
    "        l_z = (ind_pred_classes_shifted[i,:] == shifted_labels_ix[:,0]) * 1\n",
    "    else:\n",
    "        l_z = l_z + (ind_pred_classes_shifted[i,:] == shifted_labels_ix[:,0]) * 1\n",
    "\n",
    "entropy_ens_shifted = np.mean(np.minimum(l_z, ind_pred_classes_shifted.shape[0] - l_z) / (ind_pred_classes_shifted.shape[0] - np.ceil(ind_pred_classes_shifted.shape[0]/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "976df816-45da-4820-a77d-914114f139d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance single model\n",
      "Normal\tmean\tstd\tmin\tmax\n",
      "acc\t 0.8675\t0.0047\t0.8604\t0.8759\n",
      "iou\t 0.7692\t0.0076\t0.7579\t0.7823\n",
      "f1\t 0.8664\t0.0050\t0.8590\t0.8751\n",
      "\n",
      "Shifted\tmean\tstd\tmin\tmax\n",
      "acc\t 0.7570\t0.0091\t0.7402\t0.7734\n",
      "iou\t 0.6097\t0.0121\t0.5875\t0.6307\n",
      "f1\t 0.7552\t0.0094\t0.7382\t0.7715\n",
      "\n",
      "Performance ensemble (normal vs shifted)\n",
      "Acc: \t0.8940 vs 0.7902\n",
      "IoU: \t0.8110 vs 0.6534\n",
      "F1: \t0.8934 vs 0.7888\n",
      "\n",
      "\n",
      "Var ensemble 0.0439\n",
      "Entropy ensemble 0.1221\n",
      "\n",
      "\n",
      "Var ensemble shifted 0.0688\n",
      "Entropy ensemble shifted 0.1788\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance single model\")\n",
    "print(\"Normal\\tmean\\tstd\\tmin\\tmax\")\n",
    "print(\"acc\\t\", \"\\t\".join([\"%5.4f\" % n for n in stats_acc.values()]))\n",
    "print(\"iou\\t\", \"\\t\".join([\"%5.4f\" % n for n in stats_iou.values()]))\n",
    "print(\"f1\\t\", \"\\t\".join([\"%5.4f\" % n for n in stats_f1.values()]))\n",
    "print(\"\\nShifted\\tmean\\tstd\\tmin\\tmax\")\n",
    "print(\"acc\\t\", \"\\t\".join([\"%5.4f\" % n for n in stats_acc_shifted.values()]))\n",
    "print(\"iou\\t\", \"\\t\".join([\"%5.4f\" % n for n in stats_iou_shifted.values()]))\n",
    "print(\"f1\\t\", \"\\t\".join([\"%5.4f\" % n for n in stats_f1_shifted.values()]))\n",
    "\n",
    "print(\"\\nPerformance ensemble (normal vs shifted)\")\n",
    "print(\"Acc: \\t%5.4f vs %5.4f\" % (mode_acc, mode_acc_shifted))\n",
    "print(\"IoU: \\t%5.4f vs %5.4f\" % (mode_iou, mode_iou_shifted))\n",
    "print(\"F1: \\t%5.4f vs %5.4f\" % (mode_f1, mode_f1_shifted))\n",
    "    \n",
    "    \n",
    "print(\"\\n\\nVar ensemble %5.4f\" % var_ens)\n",
    "print(\"Entropy ensemble %5.4f\" % entropy_ens)\n",
    "print(\"\\n\\nVar ensemble shifted %5.4f\" % var_ens_shifted)\n",
    "print(\"Entropy ensemble shifted %5.4f\" % entropy_ens_shifted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba23deb-00c8-42a4-a386-a50b7db38c9f",
   "metadata": {},
   "source": [
    "# MC Dropout\n",
    "\n",
    "https://www.tensorflow.org/tutorials/understanding/sngp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "08db72e3-1331-4c69-8373-939bcf083f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [m for m in os.listdir(models_path) if m.endswith(\"keras\") ]\n",
    "index = 0\n",
    "print(model_names[index])\n",
    "model = tf.keras.models.load_model(os.path.join(models_path, model_names[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "98fb880f-ef62-4c1a-b9d4-fae2ad3a17e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_preds = [model(test_images, training=True) for _ in range(ens_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0c702ab6-d877-4d0a-b78b-03f891155edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_pred_classes = None\n",
    "for pred in mc_preds:\n",
    "    pred_classes = np.argmax(pred, axis=1)\n",
    "    if mc_pred_classes is None:\n",
    "        mc_pred_classes = pred_classes\n",
    "    else:\n",
    "        mc_pred_classes = np.vstack([mc_pred_classes, pred_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ad36bf6a-d1bc-4b0e-be6f-90d4c08d5d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_pred_ens = tf.reduce_mean(mc_preds, axis=0)\n",
    "mc_pred_ens_classes = np.argmax(mc_pred_ens, axis=1)\n",
    "\n",
    "mc_acc = metrics.accuracy_score(test_labels_ix, mc_pred_ens_classes)\n",
    "mc_iou = metrics.jaccard_score(test_labels_ix, mc_pred_ens_classes, average=\"weighted\")\n",
    "mc_f1 = metrics.f1_score(test_labels_ix, mc_pred_ens_classes, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "99a5a230-2b91-4b4e-86d6-740bc536b08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance\n",
    "tmp = np.stack(mc_preds, axis=1)\n",
    "var_samp_class = np.var(tmp, axis=1)\n",
    "var_samp = np.sum(var_samp_class, axis=1)\n",
    "var_mc = np.mean(var_samp)\n",
    "    \n",
    "\n",
    "# entropy\n",
    "l_z = None\n",
    "for i in range(mc_pred_classes.shape[0]):\n",
    "    if l_z is None:\n",
    "        l_z = (mc_pred_classes[i,:] == test_labels_ix[:,0]) * 1\n",
    "    else:\n",
    "        l_z = l_z + (mc_pred_classes[i,:] == test_labels_ix[:,0]) * 1\n",
    "\n",
    "entropy_mc = np.mean(np.minimum(l_z, mc_pred_classes.shape[0] - l_z) / \n",
    "                      (mc_pred_classes.shape[0] - np.ceil(ind_pred_classes.shape[0]/2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5b42e4df-1ede-469c-94db-b2a8629fb0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance deep ensemble vs MC\n",
      "Acc: \t0.8940 vs 0.8702\n",
      "IoU: \t0.8110 vs 0.7740\n",
      "F1: \t0.8934 vs 0.8699\n",
      "Var: \t0.0439 vs 0.0734\n",
      "Entropy: \t0.1221 vs 0.2805\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPerformance deep ensemble vs MC\")\n",
    "print(\"Acc: \\t%5.4f vs %5.4f\" % (mode_acc, mc_acc))\n",
    "print(\"IoU: \\t%5.4f vs %5.4f\" % (mode_iou, mc_iou))\n",
    "print(\"F1: \\t%5.4f vs %5.4f\" % (mode_f1, mc_f1))\n",
    "print(\"Var: \\t%5.4f vs %5.4f\" % (var_ens, var_mc))\n",
    "print(\"Entropy: \\t%5.4f vs %5.4f\" % (entropy_ens, entropy_mc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1dafd947-6355-4094-aaa0-be1a1d828687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h3107665801345511179_model.keras\n"
     ]
    }
   ],
   "source": [
    "print(model_names[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
